{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9083e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a1eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8795904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91c2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 505.45 Mb (76.9% reduction)\n",
      "Mem. usage decreased to 252.25 Mb (76.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_memory_usage(train)\n",
    "test = reduce_memory_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222a1060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f278</th>\n",
       "      <th>f279</th>\n",
       "      <th>f280</th>\n",
       "      <th>f281</th>\n",
       "      <th>f282</th>\n",
       "      <th>f283</th>\n",
       "      <th>f284</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.205933</td>\n",
       "      <td>0.410889</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.223633</td>\n",
       "      <td>0.423584</td>\n",
       "      <td>0.476074</td>\n",
       "      <td>0.413574</td>\n",
       "      <td>0.611816</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.181030</td>\n",
       "      <td>0.473145</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.213623</td>\n",
       "      <td>0.619629</td>\n",
       "      <td>0.441650</td>\n",
       "      <td>0.230347</td>\n",
       "      <td>0.686035</td>\n",
       "      <td>0.281982</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.307373</td>\n",
       "      <td>0.325928</td>\n",
       "      <td>0.207153</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.309814</td>\n",
       "      <td>0.493408</td>\n",
       "      <td>0.750977</td>\n",
       "      <td>0.536133</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180298</td>\n",
       "      <td>0.494629</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.223633</td>\n",
       "      <td>0.760742</td>\n",
       "      <td>0.439209</td>\n",
       "      <td>0.432129</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>0.483887</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.177124</td>\n",
       "      <td>0.495605</td>\n",
       "      <td>0.014259</td>\n",
       "      <td>0.548828</td>\n",
       "      <td>0.625488</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.561035</td>\n",
       "      <td>0.077087</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999995</td>\n",
       "      <td>0.204346</td>\n",
       "      <td>0.344727</td>\n",
       "      <td>0.262207</td>\n",
       "      <td>0.228394</td>\n",
       "      <td>0.610840</td>\n",
       "      <td>0.357422</td>\n",
       "      <td>0.490479</td>\n",
       "      <td>0.613770</td>\n",
       "      <td>0.509277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999996</td>\n",
       "      <td>0.182007</td>\n",
       "      <td>0.563965</td>\n",
       "      <td>0.242554</td>\n",
       "      <td>0.241211</td>\n",
       "      <td>0.453613</td>\n",
       "      <td>0.469482</td>\n",
       "      <td>0.477539</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>0.519043</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999997</td>\n",
       "      <td>0.250244</td>\n",
       "      <td>0.491455</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.367920</td>\n",
       "      <td>0.531738</td>\n",
       "      <td>0.598145</td>\n",
       "      <td>0.618652</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999998</td>\n",
       "      <td>0.203613</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.180176</td>\n",
       "      <td>0.213135</td>\n",
       "      <td>0.654785</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.316162</td>\n",
       "      <td>0.652344</td>\n",
       "      <td>0.397949</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999999</td>\n",
       "      <td>0.161011</td>\n",
       "      <td>0.596191</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.280273</td>\n",
       "      <td>0.580078</td>\n",
       "      <td>0.401855</td>\n",
       "      <td>0.493896</td>\n",
       "      <td>0.611816</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        f0        f1        f2        f3        f4        f5  \\\n",
       "0            0  0.205933  0.410889  0.176758  0.223633  0.423584  0.476074   \n",
       "1            1  0.181030  0.473145  0.011734  0.213623  0.619629  0.441650   \n",
       "2            2  0.182617  0.307373  0.325928  0.207153  0.605469  0.309814   \n",
       "3            3  0.180298  0.494629  0.008369  0.223633  0.760742  0.439209   \n",
       "4            4  0.177124  0.495605  0.014259  0.548828  0.625488  0.562500   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  999995  0.204346  0.344727  0.262207  0.228394  0.610840  0.357422   \n",
       "999996  999996  0.182007  0.563965  0.242554  0.241211  0.453613  0.469482   \n",
       "999997  999997  0.250244  0.491455  0.098572  0.235596  0.771484  0.367920   \n",
       "999998  999998  0.203613  0.535156  0.180176  0.213135  0.654785  0.535156   \n",
       "999999  999999  0.161011  0.596191  0.013062  0.280273  0.580078  0.401855   \n",
       "\n",
       "              f6        f7        f8  ...  f276  f277  f278  f279  f280  f281  \\\n",
       "0       0.413574  0.611816  0.534668  ...     0     1     0     0     0     0   \n",
       "1       0.230347  0.686035  0.281982  ...     0     1     0     0     0     0   \n",
       "2       0.493408  0.750977  0.536133  ...     0     0     0     1     1     0   \n",
       "3       0.432129  0.776367  0.483887  ...     0     0     0     0     1     0   \n",
       "4       0.117188  0.561035  0.077087  ...     0     1     1     0     1     0   \n",
       "...          ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "999995  0.490479  0.613770  0.509277  ...     0     0     0     1     0     0   \n",
       "999996  0.477539  0.659180  0.519043  ...     0     0     0     0     0     0   \n",
       "999997  0.531738  0.598145  0.618652  ...     0     0     0     0     0     0   \n",
       "999998  0.316162  0.652344  0.397949  ...     0     0     0     0     0     0   \n",
       "999999  0.493896  0.611816  0.531250  ...     0     0     0     0     0     0   \n",
       "\n",
       "        f282  f283  f284  target  \n",
       "0          0     0     0       1  \n",
       "1          0     0     0       1  \n",
       "2          0     0     0       1  \n",
       "3          0     0     0       1  \n",
       "4          0     1     0       1  \n",
       "...      ...   ...   ...     ...  \n",
       "999995     1     0     0       1  \n",
       "999996     0     0     1       0  \n",
       "999997     0     0     0       0  \n",
       "999998     0     0     0       1  \n",
       "999999     0     0     0       0  \n",
       "\n",
       "[1000000 rows x 287 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710f8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7666977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:-1]\n",
    "y = train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c2691a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53699121",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cadbcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(iterations = 10000, learning_rate = .05, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc8d6768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6729574\ttest: 0.6729834\ttest1: 0.6725985\tbest: 0.6725985 (0)\ttotal: 241ms\tremaining: 40m 9s\n",
      "1000:\tlearn: 0.4617345\ttest: 0.4617604\ttest1: 0.4630342\tbest: 0.4630342 (1000)\ttotal: 1m 57s\tremaining: 17m 40s\n",
      "2000:\tlearn: 0.4508551\ttest: 0.4508816\ttest1: 0.4614514\tbest: 0.4614514 (2000)\ttotal: 3m 49s\tremaining: 15m 15s\n",
      "3000:\tlearn: 0.4415388\ttest: 0.4415654\ttest1: 0.4612090\tbest: 0.4612069 (2973)\ttotal: 5m 38s\tremaining: 13m 8s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4611877686\n",
      "bestIteration = 3383\n",
      "\n",
      "Shrink model to first 3384 iterations.\n",
      "1 Fold roc_auc_score = 0.8603574762873203\n",
      "0:\tlearn: 0.6728715\ttest: 0.6728744\ttest1: 0.6728713\tbest: 0.6728713 (0)\ttotal: 160ms\tremaining: 26m 39s\n",
      "1000:\tlearn: 0.4611462\ttest: 0.4611724\ttest1: 0.4683039\tbest: 0.4683037 (999)\ttotal: 1m 58s\tremaining: 17m 47s\n",
      "2000:\tlearn: 0.4502705\ttest: 0.4502974\ttest1: 0.4667932\tbest: 0.4667760 (1974)\ttotal: 3m 50s\tremaining: 15m 22s\n",
      "3000:\tlearn: 0.4409600\ttest: 0.4409869\ttest1: 0.4666000\tbest: 0.4665913 (2985)\ttotal: 5m 40s\tremaining: 13m 14s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4665913256\n",
      "bestIteration = 2985\n",
      "\n",
      "Shrink model to first 2986 iterations.\n",
      "2 Fold roc_auc_score = 0.8562469183395404\n",
      "0:\tlearn: 0.6728148\ttest: 0.6728548\ttest1: 0.6729775\tbest: 0.6729775 (0)\ttotal: 200ms\tremaining: 33m 24s\n",
      "1000:\tlearn: 0.4608817\ttest: 0.4609081\ttest1: 0.4709201\tbest: 0.4709201 (1000)\ttotal: 1m 55s\tremaining: 17m 18s\n",
      "2000:\tlearn: 0.4500212\ttest: 0.4500477\ttest1: 0.4691996\tbest: 0.4691978 (1998)\ttotal: 3m 45s\tremaining: 14m 59s\n",
      "3000:\tlearn: 0.4406993\ttest: 0.4407263\ttest1: 0.4690261\tbest: 0.4689722 (2581)\ttotal: 5m 46s\tremaining: 13m 28s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4689721568\n",
      "bestIteration = 2581\n",
      "\n",
      "Shrink model to first 2582 iterations.\n",
      "3 Fold roc_auc_score = 0.8546857668402106\n",
      "0:\tlearn: 0.6728292\ttest: 0.6728432\ttest1: 0.6729863\tbest: 0.6729863 (0)\ttotal: 150ms\tremaining: 25m 1s\n",
      "1000:\tlearn: 0.4610274\ttest: 0.4610539\ttest1: 0.4691244\tbest: 0.4691236 (999)\ttotal: 1m 57s\tremaining: 17m 38s\n",
      "2000:\tlearn: 0.4501925\ttest: 0.4502191\ttest1: 0.4674940\tbest: 0.4674857 (1995)\ttotal: 3m 48s\tremaining: 15m 12s\n",
      "3000:\tlearn: 0.4409503\ttest: 0.4409774\ttest1: 0.4672795\tbest: 0.4672642 (2974)\ttotal: 5m 39s\tremaining: 13m 11s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4672473752\n",
      "bestIteration = 3401\n",
      "\n",
      "Shrink model to first 3402 iterations.\n",
      "4 Fold roc_auc_score = 0.8558833927904104\n",
      "0:\tlearn: 0.6729407\ttest: 0.6729523\ttest1: 0.6730181\tbest: 0.6730181 (0)\ttotal: 156ms\tremaining: 25m 59s\n",
      "1000:\tlearn: 0.4611110\ttest: 0.4611375\ttest1: 0.4691145\tbest: 0.4691145 (1000)\ttotal: 1m 58s\tremaining: 17m 47s\n",
      "2000:\tlearn: 0.4502458\ttest: 0.4502724\ttest1: 0.4674681\tbest: 0.4674473 (1943)\ttotal: 3m 58s\tremaining: 15m 53s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4673670078\n",
      "bestIteration = 2351\n",
      "\n",
      "Shrink model to first 2352 iterations.\n",
      "5 Fold roc_auc_score = 0.8558121083219488\n",
      "0:\tlearn: 0.6729335\ttest: 0.6729607\ttest1: 0.6729495\tbest: 0.6729495 (0)\ttotal: 161ms\tremaining: 26m 46s\n",
      "1000:\tlearn: 0.4614795\ttest: 0.4615053\ttest1: 0.4660088\tbest: 0.4660088 (1000)\ttotal: 1m 58s\tremaining: 17m 45s\n",
      "2000:\tlearn: 0.4506420\ttest: 0.4506687\ttest1: 0.4641427\tbest: 0.4641325 (1989)\ttotal: 3m 50s\tremaining: 15m 20s\n",
      "3000:\tlearn: 0.4413436\ttest: 0.4413704\ttest1: 0.4638461\tbest: 0.4638461 (3000)\ttotal: 5m 40s\tremaining: 13m 13s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4637976963\n",
      "bestIteration = 3304\n",
      "\n",
      "Shrink model to first 3305 iterations.\n",
      "6 Fold roc_auc_score = 0.8584561735532096\n",
      "0:\tlearn: 0.6728554\ttest: 0.6728636\ttest1: 0.6729833\tbest: 0.6729833 (0)\ttotal: 154ms\tremaining: 25m 41s\n",
      "1000:\tlearn: 0.4609864\ttest: 0.4610126\ttest1: 0.4696426\tbest: 0.4696426 (1000)\ttotal: 2m 1s\tremaining: 18m 12s\n",
      "2000:\tlearn: 0.4501075\ttest: 0.4501341\ttest1: 0.4683670\tbest: 0.4683604 (1991)\ttotal: 3m 55s\tremaining: 15m 40s\n",
      "3000:\tlearn: 0.4407484\ttest: 0.4407751\ttest1: 0.4682928\tbest: 0.4682825 (2984)\ttotal: 5m 44s\tremaining: 13m 23s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4682800632\n",
      "bestIteration = 3051\n",
      "\n",
      "Shrink model to first 3052 iterations.\n",
      "7 Fold roc_auc_score = 0.8552711690179093\n",
      "0:\tlearn: 0.6728318\ttest: 0.6728764\ttest1: 0.6729025\tbest: 0.6729025 (0)\ttotal: 150ms\tremaining: 24m 56s\n",
      "1000:\tlearn: 0.4610649\ttest: 0.4610912\ttest1: 0.4693367\tbest: 0.4693367 (1000)\ttotal: 1m 59s\tremaining: 17m 54s\n",
      "2000:\tlearn: 0.4502173\ttest: 0.4502441\ttest1: 0.4676727\tbest: 0.4676607 (1923)\ttotal: 3m 54s\tremaining: 15m 37s\n",
      "3000:\tlearn: 0.4409718\ttest: 0.4409988\ttest1: 0.4674589\tbest: 0.4673850 (2765)\ttotal: 5m 44s\tremaining: 13m 24s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4673850281\n",
      "bestIteration = 2765\n",
      "\n",
      "Shrink model to first 2766 iterations.\n",
      "8 Fold roc_auc_score = 0.8558464163480572\n",
      "0:\tlearn: 0.6728341\ttest: 0.6728422\ttest1: 0.6729067\tbest: 0.6729067 (0)\ttotal: 148ms\tremaining: 24m 36s\n",
      "1000:\tlearn: 0.4611007\ttest: 0.4611270\ttest1: 0.4689756\tbest: 0.4689756 (1000)\ttotal: 1m 57s\tremaining: 17m 38s\n",
      "2000:\tlearn: 0.4501976\ttest: 0.4502244\ttest1: 0.4674876\tbest: 0.4674840 (1996)\ttotal: 3m 48s\tremaining: 15m 13s\n",
      "3000:\tlearn: 0.4408991\ttest: 0.4409261\ttest1: 0.4673725\tbest: 0.4673220 (2773)\ttotal: 5m 36s\tremaining: 13m 5s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4673220036\n",
      "bestIteration = 2773\n",
      "\n",
      "Shrink model to first 2774 iterations.\n",
      "9 Fold roc_auc_score = 0.8560103896991751\n",
      "0:\tlearn: 0.6728555\ttest: 0.6728685\ttest1: 0.6728770\tbest: 0.6728770 (0)\ttotal: 156ms\tremaining: 26m\n",
      "1000:\tlearn: 0.4612095\ttest: 0.4612357\ttest1: 0.4678197\tbest: 0.4678197 (1000)\ttotal: 1m 58s\tremaining: 17m 45s\n",
      "2000:\tlearn: 0.4503250\ttest: 0.4503519\ttest1: 0.4662293\tbest: 0.4662130 (1961)\ttotal: 3m 51s\tremaining: 15m 23s\n",
      "3000:\tlearn: 0.4410107\ttest: 0.4410377\ttest1: 0.4660171\tbest: 0.4660046 (2800)\ttotal: 5m 42s\tremaining: 13m 19s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.4659721749\n",
      "bestIteration = 3293\n",
      "\n",
      "Shrink model to first 3294 iterations.\n",
      "10 Fold roc_auc_score = 0.8566198214608274\n"
     ]
    }
   ],
   "source": [
    "cb_pred = np.zeros((target.shape[0]))\n",
    "for i, idx in enumerate(zip(skf.split(X, y))) :\n",
    "    tr_x, tr_y = X.iloc[idx[0][0]], y.iloc[idx[0][0]]\n",
    "    val_x, val_y = X.iloc[idx[0][1]], y.iloc[idx[0][1]]\n",
    "    \n",
    "    cb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], verbose = 1000, early_stopping_rounds = 500)\n",
    "    \n",
    "    val_pred = cb.predict_proba(val_x)[:, 1]\n",
    "    \n",
    "    score = roc_auc_score(val_y, val_pred)\n",
    "    \n",
    "    print(f'{i + 1} Fold roc_auc_score = {score}')\n",
    "    \n",
    "    fold_pred = cb.predict_proba(target)[:, 1]\n",
    "    cb_pred += (fold_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79beb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state = 42, n_estimators = 5000, learning_rate = .03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3157fc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68366\tvalidation_1-logloss:0.68345\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-66bfcbbba2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         )\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_pred = np.zeros((target.shape[0]))\n",
    "for i, idx in enumerate(zip(skf.split(X, y))) :\n",
    "    tr_x, tr_y = X.iloc[idx[0][0]], y.iloc[idx[0][0]]\n",
    "    val_x, val_y = X.iloc[idx[0][1]], y.iloc[idx[0][1]]\n",
    "    \n",
    "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], verbose = 1000, early_stopping_rounds = 500)\n",
    "    \n",
    "    val_pred = xgb.predict_proba(val_x)[:, 1]\n",
    "    \n",
    "    score = roc_auc_score(val_y, val_pred)\n",
    "    \n",
    "    print(f'{i + 1} Fold roc_auc_score = {score}')\n",
    "    \n",
    "    fold_pred = xgb.predict_proba(target)[:, 1]\n",
    "    xgb_pred += (fold_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37063b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state = 42, n_estimators = 10000, learning_rate = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b3f3e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.443247\tvalid_1's binary_logloss: 0.461729\n",
      "Early stopping, best iteration is:\n",
      "[1404]\ttraining's binary_logloss: 0.433741\tvalid_1's binary_logloss: 0.461536\n",
      "1 Fold roc_auc_score = 0.8599937211379698\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.442629\tvalid_1's binary_logloss: 0.466915\n",
      "Early stopping, best iteration is:\n",
      "[1304]\ttraining's binary_logloss: 0.435396\tvalid_1's binary_logloss: 0.466801\n",
      "2 Fold roc_auc_score = 0.8558972224036924\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.442368\tvalid_1's binary_logloss: 0.469589\n",
      "Early stopping, best iteration is:\n",
      "[1164]\ttraining's binary_logloss: 0.438428\tvalid_1's binary_logloss: 0.469429\n",
      "3 Fold roc_auc_score = 0.8540578346371444\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.442592\tvalid_1's binary_logloss: 0.467645\n",
      "Early stopping, best iteration is:\n",
      "[1471]\ttraining's binary_logloss: 0.431597\tvalid_1's binary_logloss: 0.467554\n",
      "4 Fold roc_auc_score = 0.8553381498667592\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.44262\tvalid_1's binary_logloss: 0.467447\n",
      "Early stopping, best iteration is:\n",
      "[1193]\ttraining's binary_logloss: 0.437997\tvalid_1's binary_logloss: 0.4673\n",
      "5 Fold roc_auc_score = 0.8555406044611965\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.443017\tvalid_1's binary_logloss: 0.464377\n",
      "[2000]\ttraining's binary_logloss: 0.420524\tvalid_1's binary_logloss: 0.464051\n",
      "Early stopping, best iteration is:\n",
      "[1947]\ttraining's binary_logloss: 0.421654\tvalid_1's binary_logloss: 0.464029\n",
      "6 Fold roc_auc_score = 0.8580160279475714\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.442374\tvalid_1's binary_logloss: 0.468564\n",
      "Early stopping, best iteration is:\n",
      "[1257]\ttraining's binary_logloss: 0.436211\tvalid_1's binary_logloss: 0.468441\n",
      "7 Fold roc_auc_score = 0.8549672591378261\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.442565\tvalid_1's binary_logloss: 0.467561\n",
      "Early stopping, best iteration is:\n",
      "[1161]\ttraining's binary_logloss: 0.438682\tvalid_1's binary_logloss: 0.46741\n",
      "8 Fold roc_auc_score = 0.8555347620608367\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.44256\tvalid_1's binary_logloss: 0.467507\n",
      "Early stopping, best iteration is:\n",
      "[1266]\ttraining's binary_logloss: 0.436233\tvalid_1's binary_logloss: 0.467417\n",
      "9 Fold roc_auc_score = 0.8556554561720684\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.442659\tvalid_1's binary_logloss: 0.466836\n",
      "Early stopping, best iteration is:\n",
      "[1120]\ttraining's binary_logloss: 0.439748\tvalid_1's binary_logloss: 0.466741\n",
      "10 Fold roc_auc_score = 0.8559411980354081\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred = np.zeros((target.shape[0]))\n",
    "for i, idx in enumerate(zip(skf.split(X, y))) :\n",
    "    tr_x, tr_y = X.iloc[idx[0][0]], y.iloc[idx[0][0]]\n",
    "    val_x, val_y = X.iloc[idx[0][1]], y.iloc[idx[0][1]]\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], verbose = 1000, early_stopping_rounds = 500)\n",
    "    \n",
    "    val_pred = lgbm.predict_proba(val_x)[:, 1]\n",
    "    \n",
    "    score = roc_auc_score(val_y, val_pred)\n",
    "    \n",
    "    print(f'{i + 1} Fold roc_auc_score = {score}')\n",
    "    \n",
    "    fold_pred = lgbm.predict_proba(target)[:, 1]\n",
    "    lgbm_pred += (fold_pred / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddacd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4886204",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = lgbm_pred * .5 + cb_pred * .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "212be1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"1007_2nd.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
