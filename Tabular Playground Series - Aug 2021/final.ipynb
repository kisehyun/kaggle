{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000, 102), (150000, 101))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>59</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>-1.350460</td>\n",
       "      <td>42.2727</td>\n",
       "      <td>16.68570</td>\n",
       "      <td>30.3599</td>\n",
       "      <td>1.267300</td>\n",
       "      <td>0.392007</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.43990</td>\n",
       "      <td>26.854000</td>\n",
       "      <td>1.45751</td>\n",
       "      <td>0.696161</td>\n",
       "      <td>0.941764</td>\n",
       "      <td>1.828470</td>\n",
       "      <td>0.924090</td>\n",
       "      <td>2.29658</td>\n",
       "      <td>10.48980</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.784462</td>\n",
       "      <td>145</td>\n",
       "      <td>-0.463845</td>\n",
       "      <td>-0.530421</td>\n",
       "      <td>27324.9000</td>\n",
       "      <td>3.47545</td>\n",
       "      <td>160.4980</td>\n",
       "      <td>0.828007</td>\n",
       "      <td>3.735860</td>\n",
       "      <td>...</td>\n",
       "      <td>-184.13200</td>\n",
       "      <td>7.901370</td>\n",
       "      <td>1.70644</td>\n",
       "      <td>-0.494699</td>\n",
       "      <td>-2.058300</td>\n",
       "      <td>0.819184</td>\n",
       "      <td>0.439152</td>\n",
       "      <td>2.36470</td>\n",
       "      <td>1.14383</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.317816</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.432571</td>\n",
       "      <td>-0.382644</td>\n",
       "      <td>1383.2600</td>\n",
       "      <td>19.71290</td>\n",
       "      <td>31.1026</td>\n",
       "      <td>-0.515354</td>\n",
       "      <td>34.430800</td>\n",
       "      <td>...</td>\n",
       "      <td>7.43721</td>\n",
       "      <td>37.218100</td>\n",
       "      <td>3.25339</td>\n",
       "      <td>0.337934</td>\n",
       "      <td>0.615037</td>\n",
       "      <td>2.216760</td>\n",
       "      <td>0.745268</td>\n",
       "      <td>1.69679</td>\n",
       "      <td>12.30550</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.210753</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.616454</td>\n",
       "      <td>0.946362</td>\n",
       "      <td>-119.2530</td>\n",
       "      <td>4.08235</td>\n",
       "      <td>185.2570</td>\n",
       "      <td>1.383310</td>\n",
       "      <td>-47.521400</td>\n",
       "      <td>...</td>\n",
       "      <td>9.66778</td>\n",
       "      <td>0.626942</td>\n",
       "      <td>1.49425</td>\n",
       "      <td>0.517513</td>\n",
       "      <td>-10.222100</td>\n",
       "      <td>2.627310</td>\n",
       "      <td>0.617270</td>\n",
       "      <td>1.45645</td>\n",
       "      <td>10.02880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>20</td>\n",
       "      <td>0.968126</td>\n",
       "      <td>-0.092546</td>\n",
       "      <td>74.3020</td>\n",
       "      <td>12.30650</td>\n",
       "      <td>72.1860</td>\n",
       "      <td>-0.233964</td>\n",
       "      <td>24.399100</td>\n",
       "      <td>...</td>\n",
       "      <td>290.65700</td>\n",
       "      <td>15.604300</td>\n",
       "      <td>1.73557</td>\n",
       "      <td>-0.476668</td>\n",
       "      <td>1.390190</td>\n",
       "      <td>2.195740</td>\n",
       "      <td>0.826987</td>\n",
       "      <td>1.78485</td>\n",
       "      <td>7.07197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        f0   f1        f2        f3          f4        f5        f6  \\\n",
       "0   0 -0.002350   59  0.766739 -1.350460     42.2727  16.68570   30.3599   \n",
       "1   1  0.784462  145 -0.463845 -0.530421  27324.9000   3.47545  160.4980   \n",
       "2   2  0.317816   19 -0.432571 -0.382644   1383.2600  19.71290   31.1026   \n",
       "3   3  0.210753   17 -0.616454  0.946362   -119.2530   4.08235  185.2570   \n",
       "4   4  0.439671   20  0.968126 -0.092546     74.3020  12.30650   72.1860   \n",
       "\n",
       "         f7         f8  ...        f91        f92      f93       f94  \\\n",
       "0  1.267300   0.392007  ...  -42.43990  26.854000  1.45751  0.696161   \n",
       "1  0.828007   3.735860  ... -184.13200   7.901370  1.70644 -0.494699   \n",
       "2 -0.515354  34.430800  ...    7.43721  37.218100  3.25339  0.337934   \n",
       "3  1.383310 -47.521400  ...    9.66778   0.626942  1.49425  0.517513   \n",
       "4 -0.233964  24.399100  ...  290.65700  15.604300  1.73557 -0.476668   \n",
       "\n",
       "         f95       f96       f97      f98       f99  loss  \n",
       "0   0.941764  1.828470  0.924090  2.29658  10.48980    15  \n",
       "1  -2.058300  0.819184  0.439152  2.36470   1.14383     3  \n",
       "2   0.615037  2.216760  0.745268  1.69679  12.30550     6  \n",
       "3 -10.222100  2.627310  0.617270  1.45645  10.02880     2  \n",
       "4   1.390190  2.195740  0.826987  1.78485   7.07197     1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>0.812665</td>\n",
       "      <td>15</td>\n",
       "      <td>-1.239120</td>\n",
       "      <td>-0.893251</td>\n",
       "      <td>295.5770</td>\n",
       "      <td>15.87120</td>\n",
       "      <td>23.04360</td>\n",
       "      <td>0.942256</td>\n",
       "      <td>29.898000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>-422.332</td>\n",
       "      <td>-1.44630</td>\n",
       "      <td>1.69075</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>-3.010570</td>\n",
       "      <td>1.94664</td>\n",
       "      <td>0.529470</td>\n",
       "      <td>1.386950</td>\n",
       "      <td>8.78767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>0.190344</td>\n",
       "      <td>131</td>\n",
       "      <td>-0.501361</td>\n",
       "      <td>0.801921</td>\n",
       "      <td>64.8866</td>\n",
       "      <td>3.09703</td>\n",
       "      <td>344.80500</td>\n",
       "      <td>0.807194</td>\n",
       "      <td>38.421900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377179</td>\n",
       "      <td>10352.200</td>\n",
       "      <td>21.06270</td>\n",
       "      <td>1.84351</td>\n",
       "      <td>0.251895</td>\n",
       "      <td>4.440570</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.863881</td>\n",
       "      <td>11.79390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>0.919671</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.057382</td>\n",
       "      <td>0.901419</td>\n",
       "      <td>11961.2000</td>\n",
       "      <td>16.39650</td>\n",
       "      <td>273.24000</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>3224.020</td>\n",
       "      <td>-2.25287</td>\n",
       "      <td>1.55100</td>\n",
       "      <td>-0.559157</td>\n",
       "      <td>17.838600</td>\n",
       "      <td>1.83385</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>2.336870</td>\n",
       "      <td>9.05400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>0.860985</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.549509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>7501.6000</td>\n",
       "      <td>2.80698</td>\n",
       "      <td>71.08170</td>\n",
       "      <td>0.792136</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>9689.760</td>\n",
       "      <td>14.77150</td>\n",
       "      <td>1.41390</td>\n",
       "      <td>0.329272</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>2.23251</td>\n",
       "      <td>0.893348</td>\n",
       "      <td>1.359470</td>\n",
       "      <td>4.84833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>0.313229</td>\n",
       "      <td>89</td>\n",
       "      <td>0.588509</td>\n",
       "      <td>0.167705</td>\n",
       "      <td>2931.2600</td>\n",
       "      <td>4.34986</td>\n",
       "      <td>1.57187</td>\n",
       "      <td>1.118300</td>\n",
       "      <td>7.754630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862502</td>\n",
       "      <td>2693.350</td>\n",
       "      <td>44.18050</td>\n",
       "      <td>1.58020</td>\n",
       "      <td>-0.191021</td>\n",
       "      <td>26.253000</td>\n",
       "      <td>2.68238</td>\n",
       "      <td>0.361923</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>3.70660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        f0   f1        f2        f3          f4        f5         f6  \\\n",
       "0  250000  0.812665   15 -1.239120 -0.893251    295.5770  15.87120   23.04360   \n",
       "1  250001  0.190344  131 -0.501361  0.801921     64.8866   3.09703  344.80500   \n",
       "2  250002  0.919671   19 -0.057382  0.901419  11961.2000  16.39650  273.24000   \n",
       "3  250003  0.860985   19 -0.549509  0.471799   7501.6000   2.80698   71.08170   \n",
       "4  250004  0.313229   89  0.588509  0.167705   2931.2600   4.34986    1.57187   \n",
       "\n",
       "         f7         f8  ...       f90        f91       f92      f93       f94  \\\n",
       "0  0.942256  29.898000  ...  0.446389   -422.332  -1.44630  1.69075  1.059300   \n",
       "1  0.807194  38.421900  ...  0.377179  10352.200  21.06270  1.84351  0.251895   \n",
       "2 -0.003300  37.940000  ...  0.990140   3224.020  -2.25287  1.55100 -0.559157   \n",
       "3  0.792136   0.395235  ...  1.396880   9689.760  14.77150  1.41390  0.329272   \n",
       "4  1.118300   7.754630  ...  0.862502   2693.350  44.18050  1.58020 -0.191021   \n",
       "\n",
       "         f95      f96       f97       f98       f99  \n",
       "0  -3.010570  1.94664  0.529470  1.386950   8.78767  \n",
       "1   4.440570  1.90309  0.248534  0.863881  11.79390  \n",
       "2  17.838600  1.83385  0.931796  2.336870   9.05400  \n",
       "3   0.802437  2.23251  0.893348  1.359470   4.84833  \n",
       "4  26.253000  2.68238  0.361923  1.532800   3.70660  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 15, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 15, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:-1]\n",
    "y = train['loss']\n",
    "\n",
    "target = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = scaler.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from ngboost import NGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = np.zeros((target.shape[0]))\n",
    "xgb_rmse = []\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X) :\n",
    "    i += 1\n",
    "    tr_x, val_x = scaled_x[tr_idx], scaled_x[val_idx]\n",
    "    tr_y, val_y = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    \n",
    "    xgb = XGBRegressor(n_estimators = 10000, learning_rate = .005, objective = 'reg:squarederror', random_state = 42, n_jobs = -1)\n",
    "    \n",
    "    \n",
    "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], verbose = 2500, early_stopping_rounds = 1000)\n",
    "    val_pred = xgb.predict(val_x)\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, val_pred))\n",
    "    xgb_rmse.append(rmse)\n",
    "    \n",
    "    pred = xgb.predict(target) / 15\n",
    "    \n",
    "    xgb_pred += pred\n",
    "print(f'\\nRMSE of XGBoost is {np.mean(xgb_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 7.9443303\ttest: 7.8790053\tbest: 7.8790053 (0)\ttotal: 97.3ms\tremaining: 16m 12s\n",
      "2500:\tlearn: 7.8373374\ttest: 7.8213429\tbest: 7.8213429 (2500)\ttotal: 53.2s\tremaining: 2m 39s\n",
      "5000:\tlearn: 7.7653065\ttest: 7.8064105\tbest: 7.8064105 (5000)\ttotal: 1m 44s\tremaining: 1m 44s\n",
      "7500:\tlearn: 7.7015323\ttest: 7.7990985\tbest: 7.7990934 (7499)\ttotal: 2m 34s\tremaining: 51.4s\n",
      "9999:\tlearn: 7.6414627\ttest: 7.7943013\tbest: 7.7942876 (9939)\ttotal: 3m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.794287574\n",
      "bestIteration = 9939\n",
      "\n",
      "Shrink model to first 9940 iterations.\n",
      "0:\tlearn: 7.9429378\ttest: 7.8985799\tbest: 7.8985799 (0)\ttotal: 33.3ms\tremaining: 5m 33s\n",
      "2500:\tlearn: 7.8375339\ttest: 7.8249053\tbest: 7.8249053 (2500)\ttotal: 55.7s\tremaining: 2m 46s\n",
      "5000:\tlearn: 7.7653144\ttest: 7.8064777\tbest: 7.8064776 (4999)\ttotal: 1m 56s\tremaining: 1m 56s\n",
      "7500:\tlearn: 7.7010651\ttest: 7.7985743\tbest: 7.7985743 (7500)\ttotal: 2m 54s\tremaining: 58.1s\n",
      "9999:\tlearn: 7.6407820\ttest: 7.7935926\tbest: 7.7935812 (9997)\ttotal: 3m 48s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.793581177\n",
      "bestIteration = 9997\n",
      "\n",
      "Shrink model to first 9998 iterations.\n",
      "0:\tlearn: 7.9388202\ttest: 7.9564364\tbest: 7.9564364 (0)\ttotal: 29ms\tremaining: 4m 49s\n",
      "2500:\tlearn: 7.8333439\ttest: 7.8861559\tbest: 7.8861559 (2500)\ttotal: 54.7s\tremaining: 2m 44s\n",
      "5000:\tlearn: 7.7610744\ttest: 7.8699631\tbest: 7.8699588 (4999)\ttotal: 1m 48s\tremaining: 1m 48s\n",
      "7500:\tlearn: 7.6973616\ttest: 7.8623251\tbest: 7.8623234 (7499)\ttotal: 2m 47s\tremaining: 55.9s\n",
      "9999:\tlearn: 7.6372063\ttest: 7.8571781\tbest: 7.8571668 (9998)\ttotal: 3m 38s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.857166823\n",
      "bestIteration = 9998\n",
      "\n",
      "Shrink model to first 9999 iterations.\n",
      "0:\tlearn: 7.9368023\ttest: 7.9842729\tbest: 7.9842729 (0)\ttotal: 19.9ms\tremaining: 3m 18s\n",
      "2500:\tlearn: 7.8306831\ttest: 7.9201535\tbest: 7.9201535 (2500)\ttotal: 51.2s\tremaining: 2m 33s\n",
      "5000:\tlearn: 7.7586008\ttest: 7.9017581\tbest: 7.9017457 (4998)\ttotal: 1m 40s\tremaining: 1m 40s\n",
      "7500:\tlearn: 7.6950504\ttest: 7.8941881\tbest: 7.8941759 (7497)\ttotal: 2m 29s\tremaining: 49.9s\n",
      "9999:\tlearn: 7.6348470\ttest: 7.8898058\tbest: 7.8897955 (9998)\ttotal: 3m 21s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.88979546\n",
      "bestIteration = 9998\n",
      "\n",
      "Shrink model to first 9999 iterations.\n",
      "0:\tlearn: 7.9464597\ttest: 7.8488437\tbest: 7.8488437 (0)\ttotal: 25.1ms\tremaining: 4m 10s\n",
      "2500:\tlearn: 7.8399458\ttest: 7.7853609\tbest: 7.7853609 (2500)\ttotal: 50.6s\tremaining: 2m 31s\n",
      "5000:\tlearn: 7.7675150\ttest: 7.7717978\tbest: 7.7717787 (4982)\ttotal: 1m 39s\tremaining: 1m 39s\n",
      "7500:\tlearn: 7.7033659\ttest: 7.7663441\tbest: 7.7663351 (7499)\ttotal: 2m 29s\tremaining: 49.9s\n",
      "9999:\tlearn: 7.6431665\ttest: 7.7630784\tbest: 7.7630304 (9983)\ttotal: 3m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.763030441\n",
      "bestIteration = 9983\n",
      "\n",
      "Shrink model to first 9984 iterations.\n",
      "0:\tlearn: 7.9468997\ttest: 7.8425199\tbest: 7.8425199 (0)\ttotal: 20ms\tremaining: 3m 20s\n",
      "2500:\tlearn: 7.8413090\ttest: 7.7705785\tbest: 7.7705785 (2500)\ttotal: 50.1s\tremaining: 2m 30s\n",
      "5000:\tlearn: 7.7692758\ttest: 7.7512667\tbest: 7.7512667 (5000)\ttotal: 1m 40s\tremaining: 1m 40s\n",
      "7500:\tlearn: 7.7054122\ttest: 7.7439827\tbest: 7.7439750 (7496)\ttotal: 2m 28s\tremaining: 49.6s\n",
      "9999:\tlearn: 7.6453218\ttest: 7.7391635\tbest: 7.7391600 (9997)\ttotal: 3m 17s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.739159982\n",
      "bestIteration = 9997\n",
      "\n",
      "Shrink model to first 9998 iterations.\n",
      "0:\tlearn: 7.9368490\ttest: 7.9837375\tbest: 7.9837375 (0)\ttotal: 22.8ms\tremaining: 3m 48s\n",
      "2500:\tlearn: 7.8312572\ttest: 7.9152838\tbest: 7.9152838 (2500)\ttotal: 52.1s\tremaining: 2m 36s\n",
      "5000:\tlearn: 7.7587833\ttest: 7.8971780\tbest: 7.8971780 (5000)\ttotal: 1m 39s\tremaining: 1m 39s\n",
      "7500:\tlearn: 7.6945314\ttest: 7.8910003\tbest: 7.8909656 (7483)\ttotal: 2m 26s\tremaining: 49s\n",
      "9999:\tlearn: 7.6342373\ttest: 7.8873810\tbest: 7.8873771 (9998)\ttotal: 3m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.887377113\n",
      "bestIteration = 9998\n",
      "\n",
      "Shrink model to first 9999 iterations.\n",
      "0:\tlearn: 7.9385023\ttest: 7.9607059\tbest: 7.9607059 (0)\ttotal: 19.8ms\tremaining: 3m 18s\n",
      "2500:\tlearn: 7.8330089\ttest: 7.8907633\tbest: 7.8907633 (2500)\ttotal: 48.2s\tremaining: 2m 24s\n",
      "5000:\tlearn: 7.7607429\ttest: 7.8732097\tbest: 7.8732097 (5000)\ttotal: 1m 35s\tremaining: 1m 35s\n",
      "7500:\tlearn: 7.6969759\ttest: 7.8652453\tbest: 7.8652453 (7500)\ttotal: 2m 22s\tremaining: 47.5s\n",
      "9999:\tlearn: 7.6366134\ttest: 7.8606912\tbest: 7.8606773 (9998)\ttotal: 3m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.860677286\n",
      "bestIteration = 9998\n",
      "\n",
      "Shrink model to first 9999 iterations.\n",
      "0:\tlearn: 7.9386442\ttest: 7.9587519\tbest: 7.9587519 (0)\ttotal: 19.3ms\tremaining: 3m 12s\n",
      "2500:\tlearn: 7.8332304\ttest: 7.8857218\tbest: 7.8857199 (2499)\ttotal: 48.4s\tremaining: 2m 25s\n",
      "5000:\tlearn: 7.7615867\ttest: 7.8653892\tbest: 7.8653892 (5000)\ttotal: 1m 36s\tremaining: 1m 36s\n",
      "7500:\tlearn: 7.6979991\ttest: 7.8568757\tbest: 7.8568749 (7497)\ttotal: 2m 23s\tremaining: 47.7s\n",
      "9999:\tlearn: 7.6381965\ttest: 7.8514502\tbest: 7.8514502 (9999)\ttotal: 3m 9s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.851450213\n",
      "bestIteration = 9999\n",
      "\n",
      "0:\tlearn: 7.9366059\ttest: 7.9871188\tbest: 7.9871188 (0)\ttotal: 20.8ms\tremaining: 3m 27s\n",
      "2500:\tlearn: 7.8301942\ttest: 7.9249437\tbest: 7.9249437 (2500)\ttotal: 48.5s\tremaining: 2m 25s\n",
      "5000:\tlearn: 7.7576726\ttest: 7.9088254\tbest: 7.9088254 (5000)\ttotal: 1m 35s\tremaining: 1m 35s\n",
      "7500:\tlearn: 7.6937763\ttest: 7.9027641\tbest: 7.9027448 (7477)\ttotal: 2m 23s\tremaining: 47.8s\n",
      "9999:\tlearn: 7.6339151\ttest: 7.8985602\tbest: 7.8985579 (9998)\ttotal: 3m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.89855792\n",
      "bestIteration = 9998\n",
      "\n",
      "Shrink model to first 9999 iterations.\n",
      "0:\tlearn: 7.9400501\ttest: 7.9391571\tbest: 7.9391571 (0)\ttotal: 21.4ms\tremaining: 3m 34s\n",
      "2500:\tlearn: 7.8346468\ttest: 7.8681113\tbest: 7.8681113 (2500)\ttotal: 48.7s\tremaining: 2m 26s\n",
      "5000:\tlearn: 7.7624551\ttest: 7.8498895\tbest: 7.8498895 (5000)\ttotal: 1m 35s\tremaining: 1m 35s\n",
      "7500:\tlearn: 7.6984379\ttest: 7.8424171\tbest: 7.8423979 (7488)\ttotal: 2m 22s\tremaining: 47.5s\n",
      "9999:\tlearn: 7.6381623\ttest: 7.8377622\tbest: 7.8377552 (9992)\ttotal: 3m 9s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.83775524\n",
      "bestIteration = 9992\n",
      "\n",
      "Shrink model to first 9993 iterations.\n",
      "0:\tlearn: 7.9368061\ttest: 7.9843069\tbest: 7.9843069 (0)\ttotal: 20.5ms\tremaining: 3m 24s\n",
      "2500:\tlearn: 7.8315102\ttest: 7.9131939\tbest: 7.9131939 (2500)\ttotal: 48.2s\tremaining: 2m 24s\n",
      "5000:\tlearn: 7.7590792\ttest: 7.8958969\tbest: 7.8958969 (5000)\ttotal: 1m 34s\tremaining: 1m 34s\n",
      "7500:\tlearn: 7.6950081\ttest: 7.8887937\tbest: 7.8887926 (7499)\ttotal: 2m 21s\tremaining: 47.2s\n",
      "9999:\tlearn: 7.6349991\ttest: 7.8849306\tbest: 7.8849306 (9999)\ttotal: 3m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.884930556\n",
      "bestIteration = 9999\n",
      "\n",
      "0:\tlearn: 7.9313768\ttest: 8.0597254\tbest: 8.0597254 (0)\ttotal: 20.2ms\tremaining: 3m 22s\n",
      "2500:\tlearn: 7.8257737\ttest: 7.9901876\tbest: 7.9901876 (2500)\ttotal: 48.4s\tremaining: 2m 25s\n",
      "5000:\tlearn: 7.7535156\ttest: 7.9738997\tbest: 7.9738997 (5000)\ttotal: 1m 35s\tremaining: 1m 35s\n",
      "7500:\tlearn: 7.6894608\ttest: 7.9672934\tbest: 7.9672884 (7498)\ttotal: 2m 22s\tremaining: 47.3s\n",
      "9999:\tlearn: 7.6292330\ttest: 7.9636871\tbest: 7.9636871 (9999)\ttotal: 3m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.963687086\n",
      "bestIteration = 9999\n",
      "\n",
      "0:\tlearn: 7.9453594\ttest: 7.8644318\tbest: 7.8644318 (0)\ttotal: 18.5ms\tremaining: 3m 5s\n",
      "2500:\tlearn: 7.8396210\ttest: 7.7960321\tbest: 7.7960321 (2500)\ttotal: 48.7s\tremaining: 2m 26s\n",
      "5000:\tlearn: 7.7678621\ttest: 7.7798341\tbest: 7.7798341 (5000)\ttotal: 1m 38s\tremaining: 1m 38s\n",
      "7500:\tlearn: 7.7043520\ttest: 7.7722417\tbest: 7.7722408 (7498)\ttotal: 2m 26s\tremaining: 48.7s\n",
      "9999:\tlearn: 7.6442626\ttest: 7.7680526\tbest: 7.7680526 (9999)\ttotal: 3m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.768052571\n",
      "bestIteration = 9999\n",
      "\n",
      "0:\tlearn: 7.9393033\ttest: 7.9495739\tbest: 7.9495739 (0)\ttotal: 18.6ms\tremaining: 3m 5s\n",
      "2500:\tlearn: 7.8339187\ttest: 7.8772295\tbest: 7.8772295 (2500)\ttotal: 48.5s\tremaining: 2m 25s\n",
      "5000:\tlearn: 7.7619682\ttest: 7.8599207\tbest: 7.8599207 (5000)\ttotal: 1m 38s\tremaining: 1m 38s\n",
      "7500:\tlearn: 7.6983062\ttest: 7.8535920\tbest: 7.8535887 (7499)\ttotal: 2m 39s\tremaining: 53s\n",
      "9999:\tlearn: 7.6383170\ttest: 7.8493511\tbest: 7.8493467 (9992)\ttotal: 3m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 7.849346673\n",
      "bestIteration = 9992\n",
      "\n",
      "Shrink model to first 9993 iterations.\n",
      "\n",
      "RMSE of CatBoost is 7.842590407744327\n"
     ]
    }
   ],
   "source": [
    "cb_pred = np.zeros((target.shape[0]))\n",
    "cb_rmse = []\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X) :\n",
    "    i += 1\n",
    "    tr_x, val_x = scaled_x[tr_idx], scaled_x[val_idx]\n",
    "    tr_y, val_y = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    \n",
    "    cb = CatBoostRegressor(loss_function = 'RMSE', eval_metric = 'RMSE', silent = True, iterations = 10000, learning_rate = .005, random_state = 42)\n",
    "    \n",
    "    train_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    \n",
    "    cb.fit(train_data, eval_set = val_data, early_stopping_rounds = 1000, use_best_model = True, verbose = 2500)\n",
    "    rmse = cb.best_score_['validation']['RMSE']\n",
    "    cb_rmse.append(rmse)\n",
    "    pred = cb.predict(target) / 15\n",
    "    \n",
    "    cb_pred += pred\n",
    "print(f'\\nRMSE of CatBoost is {np.mean(cb_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.67263\tvalid_1's rmse: 7.80434\n",
      "[5000]\ttraining's rmse: 7.4975\tvalid_1's rmse: 7.79978\n",
      "Early stopping, best iteration is:\n",
      "[4828]\ttraining's rmse: 7.50894\tvalid_1's rmse: 7.79955\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.6728\tvalid_1's rmse: 7.80428\n",
      "[5000]\ttraining's rmse: 7.4983\tvalid_1's rmse: 7.79653\n",
      "Early stopping, best iteration is:\n",
      "[6034]\ttraining's rmse: 7.43091\tvalid_1's rmse: 7.79599\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66863\tvalid_1's rmse: 7.87166\n",
      "[5000]\ttraining's rmse: 7.49596\tvalid_1's rmse: 7.86574\n",
      "Early stopping, best iteration is:\n",
      "[6287]\ttraining's rmse: 7.41349\tvalid_1's rmse: 7.86449\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66589\tvalid_1's rmse: 7.90252\n",
      "[5000]\ttraining's rmse: 7.49275\tvalid_1's rmse: 7.8979\n",
      "[7500]\ttraining's rmse: 7.33277\tvalid_1's rmse: 7.89648\n",
      "Early stopping, best iteration is:\n",
      "[8197]\ttraining's rmse: 7.28945\tvalid_1's rmse: 7.89602\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.67365\tvalid_1's rmse: 7.77576\n",
      "[5000]\ttraining's rmse: 7.49901\tvalid_1's rmse: 7.77481\n",
      "Early stopping, best iteration is:\n",
      "[4406]\ttraining's rmse: 7.53877\tvalid_1's rmse: 7.77415\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.67632\tvalid_1's rmse: 7.75213\n",
      "[5000]\ttraining's rmse: 7.50206\tvalid_1's rmse: 7.74795\n",
      "[7500]\ttraining's rmse: 7.34082\tvalid_1's rmse: 7.74657\n",
      "Early stopping, best iteration is:\n",
      "[7086]\ttraining's rmse: 7.36701\tvalid_1's rmse: 7.7465\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66696\tvalid_1's rmse: 7.89417\n",
      "[5000]\ttraining's rmse: 7.49241\tvalid_1's rmse: 7.88802\n",
      "[7500]\ttraining's rmse: 7.33395\tvalid_1's rmse: 7.88708\n",
      "Early stopping, best iteration is:\n",
      "[6916]\ttraining's rmse: 7.37026\tvalid_1's rmse: 7.88665\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66797\tvalid_1's rmse: 7.87351\n",
      "[5000]\ttraining's rmse: 7.4952\tvalid_1's rmse: 7.8685\n",
      "Early stopping, best iteration is:\n",
      "[5306]\ttraining's rmse: 7.47501\tvalid_1's rmse: 7.86784\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66864\tvalid_1's rmse: 7.8623\n",
      "[5000]\ttraining's rmse: 7.49561\tvalid_1's rmse: 7.85712\n",
      "[7500]\ttraining's rmse: 7.33706\tvalid_1's rmse: 7.85486\n",
      "[10000]\ttraining's rmse: 7.18581\tvalid_1's rmse: 7.85337\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 7.18581\tvalid_1's rmse: 7.85337\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66444\tvalid_1's rmse: 7.90816\n",
      "[5000]\ttraining's rmse: 7.49013\tvalid_1's rmse: 7.90513\n",
      "[7500]\ttraining's rmse: 7.33199\tvalid_1's rmse: 7.90425\n",
      "Early stopping, best iteration is:\n",
      "[7278]\ttraining's rmse: 7.34587\tvalid_1's rmse: 7.90398\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.67135\tvalid_1's rmse: 7.84918\n",
      "[5000]\ttraining's rmse: 7.49737\tvalid_1's rmse: 7.84476\n",
      "Early stopping, best iteration is:\n",
      "[5924]\ttraining's rmse: 7.43663\tvalid_1's rmse: 7.84455\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66642\tvalid_1's rmse: 7.89486\n",
      "[5000]\ttraining's rmse: 7.49312\tvalid_1's rmse: 7.8879\n",
      "[7500]\ttraining's rmse: 7.33351\tvalid_1's rmse: 7.88421\n",
      "Early stopping, best iteration is:\n",
      "[7578]\ttraining's rmse: 7.32871\tvalid_1's rmse: 7.88404\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.66069\tvalid_1's rmse: 7.97122\n",
      "[5000]\ttraining's rmse: 7.48748\tvalid_1's rmse: 7.96814\n",
      "Early stopping, best iteration is:\n",
      "[4436]\ttraining's rmse: 7.52495\tvalid_1's rmse: 7.96782\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.67379\tvalid_1's rmse: 7.78019\n",
      "Early stopping, best iteration is:\n",
      "[3351]\ttraining's rmse: 7.61242\tvalid_1's rmse: 7.77861\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's rmse: 7.6679\tvalid_1's rmse: 7.86238\n",
      "[5000]\ttraining's rmse: 7.49484\tvalid_1's rmse: 7.85524\n",
      "[7500]\ttraining's rmse: 7.33687\tvalid_1's rmse: 7.85286\n",
      "Early stopping, best iteration is:\n",
      "[7734]\ttraining's rmse: 7.32231\tvalid_1's rmse: 7.85255\n",
      "\n",
      "RMSE of LGBM is 2.8013634566337084\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred = np.zeros((target.shape[0]))\n",
    "lgbm_rmse = []\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X) :\n",
    "    i += 1\n",
    "    tr_x, val_x = scaled_x[tr_idx], scaled_x[val_idx]\n",
    "    tr_y, val_y = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    \n",
    "    lgbm = LGBMRegressor(n_estimators = 10000, learning_rate = .005, objective = 'regression', metric = 'rmse', random_state = 42, n_jobs = -1)\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], verbose = 2500, early_stopping_rounds = 1000)\n",
    "    rmse = np.sqrt(list(lgbm.best_score_['valid_1'].values())[0])\n",
    "    lgbm_rmse.append(rmse)\n",
    "    \n",
    "    pred = lgbm.predict(target) / 15\n",
    "    \n",
    "    lgbm_pred += pred\n",
    "print(f'\\nRMSE of LGBM is {np.mean(lgbm_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(activation = 'relu', random_state = 42, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-abf0707e565d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtr_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtr_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_pred = np.zeros((target.shape[0]))\n",
    "mlp_rmse = []\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X) :\n",
    "    i += 1\n",
    "    tr_x, val_x = scaled_x[tr_idx], scaled_x[val_idx]\n",
    "    tr_y, val_y = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    \n",
    "    mlp = MLPRegressor(activation = 'relu', random_state = 42, batch_size = 256)\n",
    "    \n",
    "    mlp.fit(tr_x, tr_y)\n",
    "    val_pred = mlp.predict(val_x)\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, val_pred))\n",
    "    mlp_rmse.append(rmse)\n",
    "    \n",
    "    pred = mlp.predict(target) / 15\n",
    "    \n",
    "    mlp_pred += pred\n",
    "print(f'\\nRMSE of mlp is {np.mean(mlp_rmse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Make a submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['loss'] = lgbm_pred * 0.3 + cb_pred * .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('2nd.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
