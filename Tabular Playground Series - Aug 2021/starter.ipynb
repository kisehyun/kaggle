{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>59</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>-1.350460</td>\n",
       "      <td>42.2727</td>\n",
       "      <td>16.68570</td>\n",
       "      <td>30.3599</td>\n",
       "      <td>1.267300</td>\n",
       "      <td>0.392007</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.43990</td>\n",
       "      <td>26.854000</td>\n",
       "      <td>1.45751</td>\n",
       "      <td>0.696161</td>\n",
       "      <td>0.941764</td>\n",
       "      <td>1.828470</td>\n",
       "      <td>0.924090</td>\n",
       "      <td>2.29658</td>\n",
       "      <td>10.48980</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.784462</td>\n",
       "      <td>145</td>\n",
       "      <td>-0.463845</td>\n",
       "      <td>-0.530421</td>\n",
       "      <td>27324.9000</td>\n",
       "      <td>3.47545</td>\n",
       "      <td>160.4980</td>\n",
       "      <td>0.828007</td>\n",
       "      <td>3.735860</td>\n",
       "      <td>...</td>\n",
       "      <td>-184.13200</td>\n",
       "      <td>7.901370</td>\n",
       "      <td>1.70644</td>\n",
       "      <td>-0.494699</td>\n",
       "      <td>-2.058300</td>\n",
       "      <td>0.819184</td>\n",
       "      <td>0.439152</td>\n",
       "      <td>2.36470</td>\n",
       "      <td>1.14383</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.317816</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.432571</td>\n",
       "      <td>-0.382644</td>\n",
       "      <td>1383.2600</td>\n",
       "      <td>19.71290</td>\n",
       "      <td>31.1026</td>\n",
       "      <td>-0.515354</td>\n",
       "      <td>34.430800</td>\n",
       "      <td>...</td>\n",
       "      <td>7.43721</td>\n",
       "      <td>37.218100</td>\n",
       "      <td>3.25339</td>\n",
       "      <td>0.337934</td>\n",
       "      <td>0.615037</td>\n",
       "      <td>2.216760</td>\n",
       "      <td>0.745268</td>\n",
       "      <td>1.69679</td>\n",
       "      <td>12.30550</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.210753</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.616454</td>\n",
       "      <td>0.946362</td>\n",
       "      <td>-119.2530</td>\n",
       "      <td>4.08235</td>\n",
       "      <td>185.2570</td>\n",
       "      <td>1.383310</td>\n",
       "      <td>-47.521400</td>\n",
       "      <td>...</td>\n",
       "      <td>9.66778</td>\n",
       "      <td>0.626942</td>\n",
       "      <td>1.49425</td>\n",
       "      <td>0.517513</td>\n",
       "      <td>-10.222100</td>\n",
       "      <td>2.627310</td>\n",
       "      <td>0.617270</td>\n",
       "      <td>1.45645</td>\n",
       "      <td>10.02880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>20</td>\n",
       "      <td>0.968126</td>\n",
       "      <td>-0.092546</td>\n",
       "      <td>74.3020</td>\n",
       "      <td>12.30650</td>\n",
       "      <td>72.1860</td>\n",
       "      <td>-0.233964</td>\n",
       "      <td>24.399100</td>\n",
       "      <td>...</td>\n",
       "      <td>290.65700</td>\n",
       "      <td>15.604300</td>\n",
       "      <td>1.73557</td>\n",
       "      <td>-0.476668</td>\n",
       "      <td>1.390190</td>\n",
       "      <td>2.195740</td>\n",
       "      <td>0.826987</td>\n",
       "      <td>1.78485</td>\n",
       "      <td>7.07197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        f0   f1        f2        f3          f4        f5        f6  \\\n",
       "0   0 -0.002350   59  0.766739 -1.350460     42.2727  16.68570   30.3599   \n",
       "1   1  0.784462  145 -0.463845 -0.530421  27324.9000   3.47545  160.4980   \n",
       "2   2  0.317816   19 -0.432571 -0.382644   1383.2600  19.71290   31.1026   \n",
       "3   3  0.210753   17 -0.616454  0.946362   -119.2530   4.08235  185.2570   \n",
       "4   4  0.439671   20  0.968126 -0.092546     74.3020  12.30650   72.1860   \n",
       "\n",
       "         f7         f8  ...        f91        f92      f93       f94  \\\n",
       "0  1.267300   0.392007  ...  -42.43990  26.854000  1.45751  0.696161   \n",
       "1  0.828007   3.735860  ... -184.13200   7.901370  1.70644 -0.494699   \n",
       "2 -0.515354  34.430800  ...    7.43721  37.218100  3.25339  0.337934   \n",
       "3  1.383310 -47.521400  ...    9.66778   0.626942  1.49425  0.517513   \n",
       "4 -0.233964  24.399100  ...  290.65700  15.604300  1.73557 -0.476668   \n",
       "\n",
       "         f95       f96       f97      f98       f99  loss  \n",
       "0   0.941764  1.828470  0.924090  2.29658  10.48980    15  \n",
       "1  -2.058300  0.819184  0.439152  2.36470   1.14383     3  \n",
       "2   0.615037  2.216760  0.745268  1.69679  12.30550     6  \n",
       "3 -10.222100  2.627310  0.617270  1.45645  10.02880     2  \n",
       "4   1.390190  2.195740  0.826987  1.78485   7.07197     1  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f90</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250000</td>\n",
       "      <td>0.812665</td>\n",
       "      <td>15</td>\n",
       "      <td>-1.239120</td>\n",
       "      <td>-0.893251</td>\n",
       "      <td>295.5770</td>\n",
       "      <td>15.87120</td>\n",
       "      <td>23.04360</td>\n",
       "      <td>0.942256</td>\n",
       "      <td>29.898000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>-422.332</td>\n",
       "      <td>-1.44630</td>\n",
       "      <td>1.69075</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>-3.010570</td>\n",
       "      <td>1.94664</td>\n",
       "      <td>0.529470</td>\n",
       "      <td>1.386950</td>\n",
       "      <td>8.78767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250001</td>\n",
       "      <td>0.190344</td>\n",
       "      <td>131</td>\n",
       "      <td>-0.501361</td>\n",
       "      <td>0.801921</td>\n",
       "      <td>64.8866</td>\n",
       "      <td>3.09703</td>\n",
       "      <td>344.80500</td>\n",
       "      <td>0.807194</td>\n",
       "      <td>38.421900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377179</td>\n",
       "      <td>10352.200</td>\n",
       "      <td>21.06270</td>\n",
       "      <td>1.84351</td>\n",
       "      <td>0.251895</td>\n",
       "      <td>4.440570</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>0.248534</td>\n",
       "      <td>0.863881</td>\n",
       "      <td>11.79390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250002</td>\n",
       "      <td>0.919671</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.057382</td>\n",
       "      <td>0.901419</td>\n",
       "      <td>11961.2000</td>\n",
       "      <td>16.39650</td>\n",
       "      <td>273.24000</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990140</td>\n",
       "      <td>3224.020</td>\n",
       "      <td>-2.25287</td>\n",
       "      <td>1.55100</td>\n",
       "      <td>-0.559157</td>\n",
       "      <td>17.838600</td>\n",
       "      <td>1.83385</td>\n",
       "      <td>0.931796</td>\n",
       "      <td>2.336870</td>\n",
       "      <td>9.05400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250003</td>\n",
       "      <td>0.860985</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.549509</td>\n",
       "      <td>0.471799</td>\n",
       "      <td>7501.6000</td>\n",
       "      <td>2.80698</td>\n",
       "      <td>71.08170</td>\n",
       "      <td>0.792136</td>\n",
       "      <td>0.395235</td>\n",
       "      <td>...</td>\n",
       "      <td>1.396880</td>\n",
       "      <td>9689.760</td>\n",
       "      <td>14.77150</td>\n",
       "      <td>1.41390</td>\n",
       "      <td>0.329272</td>\n",
       "      <td>0.802437</td>\n",
       "      <td>2.23251</td>\n",
       "      <td>0.893348</td>\n",
       "      <td>1.359470</td>\n",
       "      <td>4.84833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250004</td>\n",
       "      <td>0.313229</td>\n",
       "      <td>89</td>\n",
       "      <td>0.588509</td>\n",
       "      <td>0.167705</td>\n",
       "      <td>2931.2600</td>\n",
       "      <td>4.34986</td>\n",
       "      <td>1.57187</td>\n",
       "      <td>1.118300</td>\n",
       "      <td>7.754630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862502</td>\n",
       "      <td>2693.350</td>\n",
       "      <td>44.18050</td>\n",
       "      <td>1.58020</td>\n",
       "      <td>-0.191021</td>\n",
       "      <td>26.253000</td>\n",
       "      <td>2.68238</td>\n",
       "      <td>0.361923</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>3.70660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        f0   f1        f2        f3          f4        f5         f6  \\\n",
       "0  250000  0.812665   15 -1.239120 -0.893251    295.5770  15.87120   23.04360   \n",
       "1  250001  0.190344  131 -0.501361  0.801921     64.8866   3.09703  344.80500   \n",
       "2  250002  0.919671   19 -0.057382  0.901419  11961.2000  16.39650  273.24000   \n",
       "3  250003  0.860985   19 -0.549509  0.471799   7501.6000   2.80698   71.08170   \n",
       "4  250004  0.313229   89  0.588509  0.167705   2931.2600   4.34986    1.57187   \n",
       "\n",
       "         f7         f8  ...       f90        f91       f92      f93       f94  \\\n",
       "0  0.942256  29.898000  ...  0.446389   -422.332  -1.44630  1.69075  1.059300   \n",
       "1  0.807194  38.421900  ...  0.377179  10352.200  21.06270  1.84351  0.251895   \n",
       "2 -0.003300  37.940000  ...  0.990140   3224.020  -2.25287  1.55100 -0.559157   \n",
       "3  0.792136   0.395235  ...  1.396880   9689.760  14.77150  1.41390  0.329272   \n",
       "4  1.118300   7.754630  ...  0.862502   2693.350  44.18050  1.58020 -0.191021   \n",
       "\n",
       "         f95      f96       f97       f98       f99  \n",
       "0  -3.010570  1.94664  0.529470  1.386950   8.78767  \n",
       "1   4.440570  1.90309  0.248534  0.863881  11.79390  \n",
       "2  17.838600  1.83385  0.931796  2.336870   9.05400  \n",
       "3   0.802437  2.23251  0.893348  1.359470   4.84833  \n",
       "4  26.253000  2.68238  0.361923  1.532800   3.70660  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 15, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 15, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = train.corr()['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cor_df = pd.DataFrame({'cor' : cor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_df['abs_cor'] = cor_df['cor'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = cor_df[cor_df.abs_cor > 0.005].index.tolist()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:-1]\n",
    "y = train['loss']\n",
    "\n",
    "target = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = scaler.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from ngboost import NGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:10.06738\tvalidation_1-rmse:10.04094\n",
      "[2456]\tvalidation_0-rmse:7.15465\tvalidation_1-rmse:7.80603\n",
      "[0]\tvalidation_0-rmse:10.06930\tvalidation_1-rmse:10.01408\n",
      "[2471]\tvalidation_0-rmse:7.15024\tvalidation_1-rmse:7.80124\n",
      "[0]\tvalidation_0-rmse:10.06345\tvalidation_1-rmse:10.09618\n",
      "[2500]\tvalidation_0-rmse:7.15453\tvalidation_1-rmse:7.86571\n",
      "[2656]\tvalidation_0-rmse:7.12090\tvalidation_1-rmse:7.86593\n",
      "[0]\tvalidation_0-rmse:10.06218\tvalidation_1-rmse:10.11556\n",
      "[2500]\tvalidation_0-rmse:7.13863\tvalidation_1-rmse:7.89171\n",
      "[3066]\tvalidation_0-rmse:7.02121\tvalidation_1-rmse:7.89484\n",
      "[0]\tvalidation_0-rmse:10.07364\tvalidation_1-rmse:9.95117\n",
      "[1897]\tvalidation_0-rmse:7.27428\tvalidation_1-rmse:7.78336\n",
      "[0]\tvalidation_0-rmse:10.07464\tvalidation_1-rmse:9.93713\n",
      "[2287]\tvalidation_0-rmse:7.18772\tvalidation_1-rmse:7.75257\n",
      "[0]\tvalidation_0-rmse:10.06112\tvalidation_1-rmse:10.12936\n",
      "[1976]\tvalidation_0-rmse:7.24971\tvalidation_1-rmse:7.89150\n",
      "[0]\tvalidation_0-rmse:10.06504\tvalidation_1-rmse:10.07296\n",
      "[2226]\tvalidation_0-rmse:7.20197\tvalidation_1-rmse:7.87458\n",
      "[0]\tvalidation_0-rmse:10.06428\tvalidation_1-rmse:10.08522\n",
      "[2397]\tvalidation_0-rmse:7.15063\tvalidation_1-rmse:7.85737\n",
      "[0]\tvalidation_0-rmse:10.06572\tvalidation_1-rmse:10.06299\n",
      "[2500]\tvalidation_0-rmse:7.12942\tvalidation_1-rmse:7.91170\n",
      "[2761]\tvalidation_0-rmse:7.07360\tvalidation_1-rmse:7.91351\n",
      "[0]\tvalidation_0-rmse:10.06757\tvalidation_1-rmse:10.03847\n",
      "[2291]\tvalidation_0-rmse:7.18120\tvalidation_1-rmse:7.84680\n",
      "[0]\tvalidation_0-rmse:10.06155\tvalidation_1-rmse:10.12382\n",
      "[2500]\tvalidation_0-rmse:7.12674\tvalidation_1-rmse:7.89506\n",
      "[2693]\tvalidation_0-rmse:7.08526\tvalidation_1-rmse:7.89639\n",
      "[0]\tvalidation_0-rmse:10.05231\tvalidation_1-rmse:10.25238\n",
      "[2047]\tvalidation_0-rmse:7.22577\tvalidation_1-rmse:7.96964\n",
      "[0]\tvalidation_0-rmse:10.07264\tvalidation_1-rmse:9.96565\n",
      "[2040]\tvalidation_0-rmse:7.23218\tvalidation_1-rmse:7.78074\n",
      "[0]\tvalidation_0-rmse:10.06356\tvalidation_1-rmse:10.09583\n",
      "[2145]\tvalidation_0-rmse:7.21551\tvalidation_1-rmse:7.86525\n"
     ]
    }
   ],
   "source": [
    "xgb_pred = np.zeros((target.shape[0]))\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X) :\n",
    "    i += 1\n",
    "    tr_x, val_x = scaled_x[tr_idx], scaled_x[val_idx]\n",
    "    tr_y, val_y = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    \n",
    "    xgb = XGBRegressor(n_estimators = 10000, learning_rate = .02, objective = 'reg:squarederror', random_state = 42)\n",
    "    \n",
    "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], verbose = 2500, early_stopping_rounds = 1000)\n",
    "    \n",
    "    pred = xgb.predict(target) / 15\n",
    "    \n",
    "    xgb_pred += pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.849700308999618"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb.best_score_['validation']['RMSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 7.9426871\ttest: 7.8777472\tbest: 7.8777472 (0)\ttotal: 18.8ms\tremaining: 3m 7s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.801766156\n",
      "bestIteration = 1308\n",
      "\n",
      "Shrink model to first 1309 iterations.\n",
      "0:\tlearn: 7.9413477\ttest: 7.8968967\tbest: 7.8968967 (0)\ttotal: 17.4ms\tremaining: 2m 54s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.802500252\n",
      "bestIteration = 931\n",
      "\n",
      "Shrink model to first 932 iterations.\n",
      "0:\tlearn: 7.9372369\ttest: 7.9547850\tbest: 7.9547850 (0)\ttotal: 18.5ms\tremaining: 3m 5s\n",
      "2500:\tlearn: 7.3628491\ttest: 7.8700425\tbest: 7.8671797 (1728)\ttotal: 44s\tremaining: 2m 11s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.867179704\n",
      "bestIteration = 1728\n",
      "\n",
      "Shrink model to first 1729 iterations.\n",
      "0:\tlearn: 7.9352126\ttest: 7.9827678\tbest: 7.9827678 (0)\ttotal: 21.7ms\tremaining: 3m 36s\n",
      "2500:\tlearn: 7.3596966\ttest: 7.9078431\tbest: 7.9022439 (1526)\ttotal: 45.6s\tremaining: 2m 16s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.902243944\n",
      "bestIteration = 1526\n",
      "\n",
      "Shrink model to first 1527 iterations.\n",
      "0:\tlearn: 7.9448309\ttest: 7.8473881\tbest: 7.8473881 (0)\ttotal: 16.7ms\tremaining: 2m 46s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.770208486\n",
      "bestIteration = 1090\n",
      "\n",
      "Shrink model to first 1091 iterations.\n",
      "0:\tlearn: 7.9453316\ttest: 7.8408495\tbest: 7.8408495 (0)\ttotal: 16.2ms\tremaining: 2m 41s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.750100326\n",
      "bestIteration = 1238\n",
      "\n",
      "Shrink model to first 1239 iterations.\n",
      "0:\tlearn: 7.9352345\ttest: 7.9823109\tbest: 7.9823109 (0)\ttotal: 18.7ms\tremaining: 3m 6s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.895431005\n",
      "bestIteration = 1065\n",
      "\n",
      "Shrink model to first 1066 iterations.\n",
      "0:\tlearn: 7.9368944\ttest: 7.9592936\tbest: 7.9592936 (0)\ttotal: 19.8ms\tremaining: 3m 17s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.871354656\n",
      "bestIteration = 1334\n",
      "\n",
      "Shrink model to first 1335 iterations.\n",
      "0:\tlearn: 7.9371005\ttest: 7.9568776\tbest: 7.9568776 (0)\ttotal: 17.5ms\tremaining: 2m 54s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.860971039\n",
      "bestIteration = 1210\n",
      "\n",
      "Shrink model to first 1211 iterations.\n",
      "0:\tlearn: 7.9349988\ttest: 7.9858616\tbest: 7.9858616 (0)\ttotal: 19ms\tremaining: 3m 9s\n",
      "2500:\tlearn: 7.3574619\ttest: 7.9013261\tbest: 7.9005388 (2254)\ttotal: 42.4s\tremaining: 2m 7s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.900538775\n",
      "bestIteration = 2254\n",
      "\n",
      "Shrink model to first 2255 iterations.\n",
      "0:\tlearn: 7.9385358\ttest: 7.9375602\tbest: 7.9375602 (0)\ttotal: 17ms\tremaining: 2m 50s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.846819278\n",
      "bestIteration = 1372\n",
      "\n",
      "Shrink model to first 1373 iterations.\n",
      "0:\tlearn: 7.9352697\ttest: 7.9830128\tbest: 7.9830128 (0)\ttotal: 17.5ms\tremaining: 2m 54s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.894258289\n",
      "bestIteration = 889\n",
      "\n",
      "Shrink model to first 890 iterations.\n",
      "0:\tlearn: 7.9298034\ttest: 8.0580410\tbest: 8.0580410 (0)\ttotal: 15.8ms\tremaining: 2m 37s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.976201932\n",
      "bestIteration = 1038\n",
      "\n",
      "Shrink model to first 1039 iterations.\n",
      "0:\tlearn: 7.9438399\ttest: 7.8629470\tbest: 7.8629470 (0)\ttotal: 17.4ms\tremaining: 2m 54s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.771078189\n",
      "bestIteration = 1457\n",
      "\n",
      "Shrink model to first 1458 iterations.\n",
      "0:\tlearn: 7.9377261\ttest: 7.9484591\tbest: 7.9484591 (0)\ttotal: 16ms\tremaining: 2m 40s\n",
      "Stopped by overfitting detector  (1000 iterations wait)\n",
      "\n",
      "bestTest = 7.858846944\n",
      "bestIteration = 1049\n",
      "\n",
      "Shrink model to first 1050 iterations.\n",
      "\n",
      "RMSE of CatBoost is 7.85129993163139\n"
     ]
    }
   ],
   "source": [
    "cb_pred = np.zeros((target.shape[0]))\n",
    "cb_rmse = []\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X) :\n",
    "    i += 1\n",
    "    tr_x, val_x = scaled_x[tr_idx], scaled_x[val_idx]\n",
    "    tr_y, val_y = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    \n",
    "    cb = CatBoostRegressor(silent = True, iterations = 10000, learning_rate = .05, random_state = 42)\n",
    "    \n",
    "    train_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    \n",
    "    cb.fit(train_data, eval_set = val_data, early_stopping_rounds = 1000, use_best_model = True, verbose = 2500)\n",
    "    rmse = cb.best_score_['validation']['RMSE']\n",
    "    cb_rmse.append(rmse)\n",
    "    pred = cb.predict(target) / 15\n",
    "    \n",
    "    cb_pred += pred\n",
    "print(f'\\nRMSE of CatBoost is {np.mean(cb_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[829]\ttraining's l2: 58.3449\tvalid_1's l2: 60.9546\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1264]\ttraining's l2: 56.757\tvalid_1's l2: 60.9063\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1075]\ttraining's l2: 57.3932\tvalid_1's l2: 61.9237\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's l2: 52.6197\tvalid_1's l2: 62.4947\n",
      "Early stopping, best iteration is:\n",
      "[1613]\ttraining's l2: 55.4837\tvalid_1's l2: 62.448\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\ttraining's l2: 59.3864\tvalid_1's l2: 60.577\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1305]\ttraining's l2: 56.6441\tvalid_1's l2: 60.1915\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's l2: 52.6024\tvalid_1's l2: 62.2273\n",
      "Early stopping, best iteration is:\n",
      "[1771]\ttraining's l2: 54.944\tvalid_1's l2: 62.2147\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's l2: 52.5984\tvalid_1's l2: 62.0675\n",
      "Early stopping, best iteration is:\n",
      "[1600]\ttraining's l2: 55.5095\tvalid_1's l2: 62.0244\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1430]\ttraining's l2: 56.1731\tvalid_1's l2: 61.8663\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1364]\ttraining's l2: 56.3117\tvalid_1's l2: 62.5175\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1395]\ttraining's l2: 56.2756\tvalid_1's l2: 61.6184\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2500]\ttraining's l2: 52.6094\tvalid_1's l2: 62.352\n",
      "Early stopping, best iteration is:\n",
      "[2305]\ttraining's l2: 53.2213\tvalid_1's l2: 62.3331\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[730]\ttraining's l2: 58.5674\tvalid_1's l2: 63.6299\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[811]\ttraining's l2: 58.4559\tvalid_1's l2: 60.5918\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1113]\ttraining's l2: 57.2661\tvalid_1's l2: 61.8063\n",
      "\n",
      "RMSE of LGBM is 7.855171505922425\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred = np.zeros((target.shape[0]))\n",
    "lgbm_rmse = []\n",
    "i = 0\n",
    "for tr_idx, val_idx in kf.split(X) :\n",
    "    i += 1\n",
    "    tr_x, val_x = scaled_x[tr_idx], scaled_x[val_idx]\n",
    "    tr_y, val_y = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    \n",
    "    lgbm = LGBMRegressor(n_estimators = 10000, learning_rate = .02, objective = 'l2', random_state = 42)\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], verbose = 2500, early_stopping_rounds = 1000)\n",
    "    rmse = np.sqrt(list(lgbm.best_score_['valid_1'].values())[0])\n",
    "    lgbm_rmse.append(rmse)\n",
    "    \n",
    "    pred = lgbm.predict(target) / 15\n",
    "    \n",
    "    lgbm_pred += pred\n",
    "print(f'\\nRMSE of LGBM is {np.mean(lgbm_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Make a submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['loss'] = lgbm_pred * 0.3 + cb_pred * .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('2nd.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
