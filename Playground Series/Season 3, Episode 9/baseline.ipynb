{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "41419d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from ngboost import NGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81ec3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad9651e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['feature_mean'] = train.iloc[:, 1:-1].mean(axis = 1)\n",
    "test['feature_mean'] = test.iloc[:, 1:].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c418b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 8, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40b4292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bda44a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['id', 'Strength'], axis = 1)\n",
    "target = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12b9548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(ss.fit_transform(X), columns = X.columns)\n",
    "y = train['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6058c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(ss.transform(target), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c0b4606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold RMSE : 11.678100301248495 Iterations : 816\n",
      "2 Fold RMSE : 11.669365898827962 Iterations : 539\n",
      "3 Fold RMSE : 12.344550467056505 Iterations : 375\n",
      "4 Fold RMSE : 12.25873345334013 Iterations : 263\n",
      "5 Fold RMSE : 11.978393727501528 Iterations : 1068\n",
      "6 Fold RMSE : 11.833102523129963 Iterations : 243\n",
      "7 Fold RMSE : 12.13728424624623 Iterations : 488\n",
      "8 Fold RMSE : 12.474234326004929 Iterations : 590\n",
      "\n",
      "CatBoostRegressor Mean of RMSE : 12.046720617919467\n",
      "CPU times: user 31.8 s, sys: 19.4 s, total: 51.2 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cb_pred = np.zeros(target.shape[0])\n",
    "cb_rmse = 0\n",
    "for i, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    cb = CatBoostRegressor(random_state = 42, learning_rate = 0.02, n_estimators = 10000, max_depth = 5)\n",
    "    cb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 1500, verbose = 0)\n",
    "    \n",
    "    val_pred = cb.predict(val_x)\n",
    "    fold_rmse = mean_squared_error(val_y, val_pred) ** 0.5\n",
    "    cb_rmse += fold_rmse / kf.n_splits\n",
    "    print(f'{i + 1} Fold RMSE : {fold_rmse} Iterations : {cb.best_iteration_}')\n",
    "    \n",
    "    fold_pred = cb.predict(target) / kf.n_splits\n",
    "    cb_pred += fold_pred\n",
    "    \n",
    "print(f'\\n{cb.__class__.__name__} Mean of RMSE : {cb_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8777f1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold RMSE : 11.750850226189874 Iterations : 406\n",
      "2 Fold RMSE : 11.738872531799089 Iterations : 176\n",
      "3 Fold RMSE : 12.406382110401243 Iterations : 184\n",
      "4 Fold RMSE : 12.39185509272988 Iterations : 151\n",
      "5 Fold RMSE : 12.04011432795785 Iterations : 268\n",
      "6 Fold RMSE : 11.958778739520701 Iterations : 141\n",
      "7 Fold RMSE : 12.22266760577524 Iterations : 225\n",
      "8 Fold RMSE : 12.58022254523948 Iterations : 191\n",
      "\n",
      "LGBMRegressor Mean of RMSE : 12.13621789745167\n",
      "CPU times: user 48.2 s, sys: 4.02 s, total: 52.3 s\n",
      "Wall time: 6.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_pred = np.zeros(target.shape[0])\n",
    "lgbm_rmse = 0\n",
    "for i, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    lgbm = LGBMRegressor(random_state = 42, learning_rate = 0.02, n_estimators = 10000, max_depth = 5, objective = 'l2')\n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 1500, verbose = 0)\n",
    "    \n",
    "    val_pred = lgbm.predict(val_x)\n",
    "    fold_rmse = mean_squared_error(val_y, val_pred) ** 0.5\n",
    "    lgbm_rmse += fold_rmse / kf.n_splits\n",
    "    print(f'{i + 1} Fold RMSE : {fold_rmse} Iterations : {lgbm.best_iteration_}')\n",
    "    \n",
    "    fold_pred = lgbm.predict(target) / kf.n_splits\n",
    "    lgbm_pred += fold_pred\n",
    "    \n",
    "print(f'\\n{lgbm.__class__.__name__} Mean of RMSE : {lgbm_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb2ca392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold RMSE : 11.775904315960506 Iterations : 197\n",
      "2 Fold RMSE : 11.75518671346508 Iterations : 210\n",
      "3 Fold RMSE : 12.40462780961416 Iterations : 363\n",
      "4 Fold RMSE : 12.401486497449048 Iterations : 259\n",
      "5 Fold RMSE : 12.079413652820365 Iterations : 315\n",
      "6 Fold RMSE : 11.921972003558842 Iterations : 176\n",
      "7 Fold RMSE : 12.228999149679918 Iterations : 246\n",
      "8 Fold RMSE : 12.598531128606192 Iterations : 562\n",
      "\n",
      "XGBRegressor Mean of RMSE : 12.145765158894266\n",
      "CPU times: user 2min 37s, sys: 16.7 s, total: 2min 54s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb_pred = np.zeros(target.shape[0])\n",
    "xgb_rmse = 0\n",
    "for i, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    xgb = XGBRegressor(random_state = 42, learning_rate = 0.02, n_estimators = 10000, max_depth = 5, objective = 'reg:squarederror')\n",
    "    xgb.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], early_stopping_rounds = 1500, verbose = 0)\n",
    "    \n",
    "    val_pred = xgb.predict(val_x)\n",
    "    fold_rmse = mean_squared_error(val_y, val_pred) ** 0.5\n",
    "    xgb_rmse += fold_rmse / kf.n_splits\n",
    "    print(f'{i + 1} Fold RMSE : {fold_rmse} Iterations : {xgb.best_iteration}')\n",
    "    \n",
    "    fold_pred = xgb.predict(target) / kf.n_splits\n",
    "    xgb_pred += fold_pred\n",
    "    \n",
    "print(f'\\n{xgb.__class__.__name__} Mean of RMSE : {xgb_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6e46c9b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold RMSE : 11.717147680813813\n",
      "2 Fold RMSE : 11.711753657330577\n",
      "3 Fold RMSE : 12.410394805098608\n",
      "4 Fold RMSE : 12.379907770711252\n",
      "5 Fold RMSE : 12.077621201077793\n",
      "6 Fold RMSE : 11.912707878556965\n",
      "7 Fold RMSE : 12.201489906653638\n",
      "8 Fold RMSE : 12.598401876223646\n",
      "\n",
      "NGBRegressor Mean of RMSE : 12.126178097058288\n",
      "CPU times: user 32.4 s, sys: 361 ms, total: 32.8 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ngb_pred = np.zeros(target.shape[0])\n",
    "ngb_rmse = 0\n",
    "for i, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
    "    val_x, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    \n",
    "    ngb = NGBRegressor(random_state = 42, learning_rate = 0.03, n_estimators = 2000, verbose = 0)\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 200)\n",
    "    \n",
    "    val_pred = ngb.predict(val_x)\n",
    "    fold_rmse = mean_squared_error(val_y, val_pred) ** 0.5\n",
    "    ngb_rmse += fold_rmse / kf.n_splits\n",
    "    print(f'{i + 1} Fold RMSE : {fold_rmse}')\n",
    "    \n",
    "    fold_pred = ngb.predict(target) / kf.n_splits\n",
    "    ngb_pred += fold_pred\n",
    "    \n",
    "print(f'\\n{ngb.__class__.__name__} Mean of RMSE : {ngb_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65c73fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b05707a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Strength'] = (cb_pred * 0.4 + ngb_pred * 0.25 + lgbm_pred * 0.2 + xgb_pred * 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2fc6157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lgbm_catboost_xgb_ngb.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a828ad",
   "metadata": {},
   "source": [
    "***\n",
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1178647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392a41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7271a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(ss.fit_transform(X), dtype = torch.float)\n",
    "y = torch.tensor(y, dtype = torch.long)\n",
    "target = torch.tensor(ss.transform(target), dtype = torch.float)\n",
    "_ = torch.zeros(target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cd87126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module) :\n",
    "    \n",
    "    def __init__(self, feature) :\n",
    "        \n",
    "        super(NN, self).__init__()\n",
    "        self.layer_1 = nn.Linear(feature.shape[1], 32)\n",
    "#        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu_1 = nn.LeakyReLU()\n",
    "        self.layer_2 = nn.Linear(32, 16)\n",
    " #       self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu_2 = nn.LeakyReLU()\n",
    "        self.layer_3 = nn.Linear(16, 4)\n",
    "  #      self.bn3 = nn.BatchNorm1d(4)\n",
    "        self.relu_3 = nn.LeakyReLU()\n",
    "        self.layer_4 = nn.Linear(4, 1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        \n",
    "        x = self.layer_1(x)\n",
    "     #   x = self.bn1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.layer_2(x)\n",
    "      #  x = self.bn2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.layer_3(x)\n",
    "       # x = self.bn3(x)\n",
    "        x = self.relu_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f255c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_epochs, tr_loader, val_loader, criterion) :\n",
    "    \n",
    "    for epoch in range(num_epochs) :\n",
    "        \n",
    "        model.train()\n",
    "        tr_losses = 0\n",
    "        \n",
    "        for xx, yy in tr_loader :\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            xx = xx.to('cpu')\n",
    "            yy = yy.to('cpu')\n",
    "            pred = model(xx)\n",
    "            \n",
    "            loss = criterion(pred, yy)\n",
    "            loss.backward()\n",
    "            tr_losses += loss.item() / len(tr_loader)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        with torch.no_grad() :\n",
    "            \n",
    "            model.eval()\n",
    "            val_losses = 0\n",
    "            epoch_rmse = 0\n",
    "            \n",
    "            for xx, yy in val_loader :\n",
    "                \n",
    "                xx = xx.to('cpu')\n",
    "                yy = yy.to('cpu')\n",
    "                pred = model(xx)\n",
    "                \n",
    "                loss = criterion(pred, yy)\n",
    "                val_losses += loss.item() / len(val_loader)\n",
    "                batch_rmse = mean_squared_error(yy, pred) ** 0.5\n",
    "                epoch_rmse += batch_rmse / len(val_loader)\n",
    "                \n",
    "        print(f\"{epoch + 1} Epoch Train Loss : {round(tr_losses, 4)} Validation Loss : {round(val_losses, 4)} Validation RMSE : {round(epoch_rmse, 4)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d09235e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(y_actual, y_pred) :\n",
    "    \n",
    "    return torch.sqrt(torch.mean((y_pred - y_actual) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b146652",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nn_pred = np.zeros(target.shape[0])\n",
    "nn_rmse = 0\n",
    "for i, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
    "    tr_x, tr_y = X[tr_idx], y[tr_idx]\n",
    "    val_x, val_y = X[val_idx], y[val_idx]\n",
    "    \n",
    "    tr_ds = TensorDataset(tr_x, tr_y)\n",
    "    val_ds = TensorDataset(val_x, val_y)\n",
    "    te_ds = TensorDataset(target, _)\n",
    "\n",
    "    tr_loader = DataLoader(tr_ds, batch_size = 32, shuffle = True, drop_last = True)\n",
    "    val_loader = DataLoader(val_ds, batch_size = 32, shuffle = False, drop_last = False)\n",
    "    te_loader = DataLoader(te_ds, batch_size = 32, shuffle = False, drop_last = False)\n",
    "\n",
    "    model = NN(X).to('cpu')\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.02)\n",
    "    criterion = RMSELoss\n",
    "\n",
    "    best_model = train(model, optimizer, 15, tr_loader, val_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
